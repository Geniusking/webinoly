#!/bin/bash


bucket_validation() {
	local bucketname=$(echo $1 | cut -d "/" -f 1)
	local bucketfolder=$(echo $1 | cut -d "/" -f 2- -s)
	
	# Only numerals 0-9, basic Latin letters (only lowercase) and underscore.
	# https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html
	if [[ -z $1 || -z $bucketname ]]; then
		echo "${red}[ERROR] Please, enter a valid bucket name! ${end}"
		exit 1
	elif ! [[ $bucketname =~ ^[0-9a-z\/-]+$ ]] || [[ -z $bucketname || $(echo $bucketname | cut -c-1) =~ [-|\/] || ${#bucketname} -gt 63 || ${#bucketname} -lt 3 ]]; then
		echo "${red}[ERROR] Bucket names can only contain lowercase letters, numbers or hyphens; must start with a letter or number and must be at least 3 and no more than 63 characters long.${end}"
		exit 1
	elif [[ -n $bucketfolder ]] && ! [[ $bucketfolder =~ ^[0-9a-zA-Z\/-_\!\.\*\'\)\(]+$ ]]; then
		if [[ $(is_url_path /$bucketfolder) == "true" ]]; then
			echo "${red}[WARNING] Your bucket folder name contain some characters that might require special handling!"
			echo "More info: https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html#object-key-guidelines ${end}"
		else
			echo "${red}[ERROR] Invalid bucket folder name.${end}"
			exit 1
		fi
	fi
}


bkp_local_db() {
	check_for_mysql_client
	
	if [[ ( -z $wp || $wp == "true") && ( -z $dbname || $dbname == "true" ) ]]; then
		read -p "${gre}WordPress site (domain) or Database name: ${end}" dbq
		if [[ -n $dbq && -f /etc/nginx/sites-available/$dbq ]]; then
			wp=$dbq
		elif [[ -n $dbq ]]; then
			dbname=$dbq
			wp=""
		else
			echo "${red}[ERROR] Invalid value!${end}"
			exit 1
		fi
	fi
	
	if [[ -n $wp ]]; then
		if [[ $(is_wp $wp $subfolder) != "true"  ]]; then
			echo "${red}[ERROR] Please, enter a valid WP site!${end}"
			exit 1
		elif [[ $(is_wp_installed $wp) != "true"  ]]; then
			echo "${red}[ERROR] Your WP site database is still empty!${end}"
			exit 1
		else
			wp_dbdata $wp
			local dbname=$wp_dbname
			local dburl=$wp_dburl
			local dbport=$wp_dbport
			local uroot=$wp_uroot
			local proot$wp_proot
		fi
	else
		if [[ -z $external_db ]]; then
			local checkdbname=$(sudo mysqlshow --user=admin -p$ADMIN_PASS | grep -ow $dbname)
		else
			local dbdata=${external_db:1:-1}
			local uroot=$(echo "${dbdata}" | cut -d',' -f 1 -s)
			local proot=$(echo "${dbdata}" | cut -d',' -f 2 -s)
			local dbhost=$(echo "${dbdata}" | cut -d',' -f 3 -s)
			local dburl=$(echo "$dbhost" | cut -f 1 -d ':')
			local dbport=$(echo "$dbhost" | cut -f 2 -d ':' -s)
		
			if [[ $(echo "${external_db}" | cut -c-1) != "[" || $(echo "${external_db}" | rev | cut -c-1) != "]" || -z $uroot || -z $proot || -z $dburl || -z $dbport ]]; then
				echo "${red}[ERROR] Invalid data for External Database!${end}"
				exit 1
			elif [[ $(check_mysql_connection $dburl $dbport $uroot $proot) != "true" ]]; then
				echo "${red}[ERROR] Cannot connect with your External Database!${end}"
				exit 1
			fi
			
			local checkdbname=$(sudo mysqlshow -h "$dburl" -P "$dbport" -u"$dburoot" -p"$dbproot" | grep -ow $dbname)
		fi
		
		if [[ $checkdbname != $dbname  ]]; then
			echo "${red}[ERROR] Database not found!${end}"
			exit 1
		fi
		
	fi
	
	# Always go with default path, except if parameter is entered and empty
	[[ $destination == "true" ]] && read -p "${gre}Destination: ${end}" destination
	[[ -n $wp ]] && local fn=$wp || local fn=$dbname
	
	if [[ -z $destination || $destination == "default" ]]; then
		destination="$HOME/webinoly-backups/$fn"
		sudo mkdir -p $destination
	
	# Must start with / and can not end with /
	elif [[ ! -d $destination && $(echo "${destination}" | cut -c-1) == "/" && $(echo "${destination}" | rev | cut -c-1) != "/" ]]; then
		sudo mkdir -p $destination
	fi
	if [[ ! -d $destination || $(echo "${destination}" | rev | cut -c-1) == "/" ]]; then
		echo "${red}[ERROR] Please, enter a valid destination path!${end}"
		exit 1
	fi
	
	local filename="webinoly-backup-db_${fn}_$(date +%F)-$(date +%T).sql"
	if [[ $wp_dbhost == "localhost" && -z $dbhost ]]; then
		sudo mysqldump --user=admin --password=$ADMIN_PASS --single-transaction --lock-tables --quick --databases $dbname > $destination/$filename
	else
		sudo mysqldump -h "$dburl" -P "$dbport" -u"$uroot" -p"$proot" --single-transaction --lock-tables --quick --databases $dbname > $destination/$filename
	fi
	
	if [[ -s $destination/$filename ]]; then
		echo "${gre}Database local backup successfully done!${end}${dim} ($destination/$filename)${end}"
		[[ -n $bucket ]] && sudo webinoly -backup=s3 -send-to-s3=$destination/$filename -bucket=$bucket
		[[ -n $max && $max =~ ^[0-9]+$ ]] && sudo ls -1t $destination | tail -n +$((max+1)) | xargs -d '\n' -I '%' sudo rm -f $destination/%
	else
		echo "${red}[ERROR] Database backup failed!${end}"
		exit 1
	fi
}


check_duply_profile() {
	if [[ ! -d $HOME/.duply/$profile ]]; then
		echo "${red}[ERROR] Backup profile not found!${end}"
		exit 1
	fi
}


bkp_s3_profile() {
	if [[ ! -s $HOME/.aws/credentials && $(conf_read awsiamrole) != true ]]; then
		echo "${red}[ERROR] AWS S3 Credentials not found!${end}"
		exit 1
	fi
	
	if [[ $profile == "true" || -z $profile ]]; then
		echo ""
		read -p "${gre}Profile name: ${end}" profile
		
		if [[ -z $profile ]]; then
			echo "${red}[ERROR] Profile name is empty!${end}"
			exit 1
		fi
	fi
	
	
	if [[ -n $run ]]; then
		check_duply_profile
		sudo duply $profile backup_verify_purge --force --allow-source-mismatch
		
	elif [[ -n $info ]]; then
		check_duply_profile
		
		tar=$(grep -E "^TARGET[ ]?=" $HOME/.duply/$profile/conf | cut -f 2 -d "'" )
		sou=$(grep -E "^SOURCE[ ]?=" $HOME/.duply/$profile/conf | cut -f 2 -d "'" )
		age=$(grep -E "^MAX_AGE[ ]?=" $HOME/.duply/$profile/conf | cut -f 2 -d "=" )
		par=$(grep "s3-use-new-style" $HOME/.duply/$profile/conf | cut -f 2 -d '"' )
			
		echo ""
		echo "${blu}S3 Bucket:${end} $tar"
		echo "${blu}Source:${end} $sou"
		echo "${blu}Max_Age:${end} $age"
		echo "${blu}Parameters:${end} $par"
		echo ""
	
	elif [[ -n $delete ]]; then
		check_duply_profile
		
		sudo rm -rf $HOME/.duply/$profile
		echo "${gre}Backup profile ${blu}'$profile'${gre} was successfully deleted!${end}"
		
	elif [[ -n $restore ]]; then
		check_duply_profile
		
		# Temporary check!!!! Should be removed soon!!!
		if [[ $restore != "true" && -z $destination ]]; then
			echo "${red}[ERROR] Backup Restore syntax has changed, destination paramater is needed!${end}"
			exit 1
		fi
		
		if [[ -z $destination || $destination == "true" ]]; then
			echo ""
			# We don't do a destination path validation because duply can handle it better.
			read -p "${gre}Restore destination folder: ${end}" destination
			
			if [[ -z $destination ]]; then
				echo "${red}[ERROR] Invalid destination path!${end}"
				exit 1
			fi
		fi
		
		[[ $restore != "true" ]] && sudo duply $profile fetch $restore $destination $date || sudo duply $profile restore $destination $date
		
		
	elif [[ -n $add_db_pre && -n $list ]]; then
		check_duply_profile
		
		if [[ -s $HOME/.duply/$profile/pre ]]; then
			echo ""
			echo "${gre}The following lines will be executed every time just before (PRE)${blu} '$profile' ${gre}backup is run:${blu}"
			cat $HOME/.duply/$profile/pre
			echo "${end}"
		else
			echo "${red}[ERROR] PRE Database backups is empty!${end}"
			exit 1
		fi
	
	
	elif [[ -n $add_db_pre && -n $purge ]]; then
		check_duply_profile	
		sudo rm -rf $HOME/.duply/$profile/pre
		echo "${gre}PRE Database backups for${blu} '$profile' ${gre}has been successfully removed!${end}"
		
		
	elif [[ -n $add_db_pre ]]; then
		check_duply_profile
		
		[[ $add_db_pre == "true" ]] &&	read -p "${gre}WordPress site: ${end}" add_db_pre
		# we dont check is_wp_installed because at this point we are still not doing a backup, just setting it.
		if [[ -z $add_db_pre || $(is_wp $add_db_pre $subfolder) != "true"  ]]; then
			echo "${red}[ERROR] Please, enter a valid WP site!${end}"
			exit 1
		fi
		
		wp_dbdata $add_db_pre false
		if [[ $wp_dbhost != "localhost" && -z $(conf_read external-dbu) && -z $(conf_read external-dbp) ]]; then
			echo "${red}[ERROR] Database host is not localhost!${end}"
			exit 1
		fi
		
		[[ -z $destination || $destination == "true" ]] && destination="default"
		[[ -z $max && $destination == "default" ]] && max="5"
		[[ -n $max && $max =~ ^[0-9]+$ ]] && local param="-max=$max "
		[[ -n $bucket && $bucket != "true" ]] && local param="${param}-bucket=$bucket "
		[[ -n $subfolder ]] && local param="${param}-subfolder=$subfolder"
		
		[[ ! -f $HOME/.duply/$profile/pre ]] && sudo touch $HOME/.duply/$profile/pre
		echo "sudo webinoly -backup=local -wp=$add_db_pre -destination=$destination $param" >> $HOME/.duply/$profile/pre
		echo "${gre}Database backup will run each time you run your S3 backup!${end}"
	
	else
		if [[ -d $HOME/.duply/$profile ]]; then
			echo "${red}[ERROR] Can not create profile${blu} '$profile' ${red}because already exists!${end}"
			exit 1
		fi
	
		[[ -z $bucket || $bucket == "true" ]] &&	read -p "${gre}S3 Bucket name: ${end}" bucket
		bucket_validation $bucket
		
		[[ -z $source || $source == "true" ]] && read -p "${gre}Source path: ${end}" source
		if [[ -z $source || ! -d $source ]]; then
			echo "${red}[ERROR] Please, enter a valid source folder and bucket name!${end}"
			exit 1
		fi
		
		sudo duply $profile create
		[[ -z $max_age ]] && max_age="1M"
		sudo sed -i -E "/^[#]?GPG_KEY=/c GPG_KEY='disabled'" $HOME/.duply/$profile/conf
		sudo sed -i -E "/^[#]?GPG_PW=/c #GPG_PW='_GPG_PASSWORD_'" $HOME/.duply/$profile/conf
		sudo sed -i -E "/^[#]?SOURCE=/c SOURCE='$source'" $HOME/.duply/$profile/conf
		sudo sed -i -E "/^[#]?MAX_AGE=/c MAX_AGE=$max_age" $HOME/.duply/$profile/conf
		
		if [[ $(check_osname) == "focal" ]]; then
			sudo sed -i -E "/^[#]?TARGET=/c TARGET='boto3+s3://${bucket}'" $HOME/.duply/$profile/conf
		else
			sudo sed -i -E "/^[#]?TARGET=/c TARGET='s3+http://${bucket}'" $HOME/.duply/$profile/conf
			sudo echo 'DUPL_PARAMS="$DUPL_PARAMS --s3-use-new-style "' >> $HOME/.duply/$profile/conf
		fi
		
		echo "${gre}Backup profile ${blu}'$profile'${gre} was successfully created!${end}"
	fi
}


bkp_s3_list() {
	echo ""
	if [[ -d $HOME/.duply ]];  then
		for f in $HOME/.duply/*
		do 
			[[ -d $f ]] && pro=$(echo $f | rev | cut -f 1 -d "/" -s | rev)
			[[ -f $f/conf ]] && fail="" || fail="${red}(fail)${end}"
			[[ -n $raw || $list == "raw" ]] && outlist="$pro" || outlist=" ${gre}+ $pro ${end}${fail}"
			if [[ -n $pro ]]; then
				echo "$outlist"
				nonemptylist=true
			fi
		done
	fi
	
	[[ -z $nonemptylist && -z $raw && $list != "raw" ]] && echo "${blu}[Empty] No profiles were found!${end}"
	echo ""
}


s3_send() {
	if [[ ! -s $HOME/.aws/credentials && $(conf_read awsiamrole) != true ]]; then
		echo "${red}[ERROR] AWS S3 Credentials not found!${end}"
		exit 1
	fi
	
	[[ -z $send_to_s3 || $send_to_s3 == "true" ]] && read -p "${gre}File to send: ${end}" send_to_s3
	if [[ ! -f $send_to_s3 ]]; then
		echo "${red}[ERROR] File not found!${end}"
		exit 1
	fi
	
	[[ -z $bucket || $bucket == "true" ]] &&	read -p "${gre}S3 Bucket name: ${end}" bucket
	bucket_validation $bucket
	
	folder=$(echo $bucket | cut -f 2- -d "/" -s)
	[[ -n $folder ]] && keyfol="${folder}/"
	[[ -n $folder ]] && folder="/${folder}/"
	
	export keyfol
	export folder
	export bucket=$(echo $bucket | cut -f 1 -d "/")
	export send_to_s3

	if [[ $(check_osname) == "focal" ]]; then
		python3 - &>/dev/null <<END
import os,boto3

filepath = os.environ['send_to_s3']
BUCKET = os.environ['bucket']
folder = os.environ['keyfol']

s3_client = boto3.client('s3')
s3_client.upload_file(filepath, BUCKET, folder + filepath.split('/')[-1])

END
	else
		python - &>/dev/null <<END
import os,boto

filepath = os.environ['send_to_s3']
BUCKET = os.environ['bucket']
folder = os.environ['folder']

conn = boto.connect_s3()
bucket = conn.lookup(BUCKET)
k = bucket.new_key(folder + filepath.split('/')[-1])
k.set_contents_from_filename(filepath)

END
	fi
	
	if [[ $? == 0 ]]; then
		unset send_to_s3
		unset folder
		unset bucket
		echo "${gre}File was sent to S3 successfully!${end}"
	else
		unset send_to_s3
		unset folder
		unset bucket
		echo "${red}[ERROR] Can not connect with your bucket!${end}"
		exit 1
	fi
	
}


bkp_wizard() {
	echo "${gre}"
	echo " ***********************************"
	echo " ************  Backups  ************"
	echo " ***********************************"
	echo "${blu}"
	echo " 1 - Add AWS S3 Credentials"
	echo " 2 - AWS S3 directory backup"
	echo " 3 - WordPress Database local backup"
	echo " 4 - Restore backup from S3"
	echo " 5 - Run S3 backup"
	echo " 6 - Delete profile"
	echo " 7 - Profile info"
	echo " 8 - List profiles"
	echo "${gre}"
	read -p "What do you want to do? ${end}" wzd
	echo ""
	
	if [[ $wzd == 1 ]]; then
		webinoly -aws-s3-credentials
	elif [[ $wzd == 2 ]]; then
		bkp_s3_profile
	elif [[ $wzd == 3 ]]; then
		bkp_local_db
	elif [[ $wzd == 4 ]]; then
		restore="true"
		bkp_s3_profile
	elif [[ $wzd == 5 ]]; then
		run="true"
		bkp_s3_profile
	elif [[ $wzd == 6 ]]; then
		delete="true"
		bkp_s3_profile
	elif [[ $wzd == 7 ]]; then
		info="true"
		bkp_s3_profile
	elif [[ $wzd == 8 ]]; then
		bkp_s3_list
	else
		echo "${red}[ERROR] Please, enter a valid option!${end}"
		exit 1
	fi
}
